{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the great_expectations library, which is a Python package for data validation and data quality\n",
    "# Great Expectations is a framework for data validation and data quality that allows you to define expectations for your data\n",
    "# and then validate your data against those expectations.\n",
    "import great_expectations as gx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Great Expectations context object, which is the main entry point for interacting with the library\n",
    "# The context object is the central hub of the Great Expectations framework, and it provides access to all the other components.\n",
    "context = gx.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new data source to the context, which is a source of data that can be validated\n",
    "# In this case, we're adding a pandas data source, which is a type of data source that can be used with Pandas DataFrames\n",
    "# A data source is a source of data that can be validated using Great Expectations.\n",
    "# It could be a CSV file, a database, or any other type of data storage.\n",
    "datasource = context.sources.add_pandas(name=\"example datasource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new asset to the data source, which is a specific dataset or file that can be validated\n",
    "# In this case, we're adding a CSV asset, which is a type of asset that represents a CSV file\n",
    "# The filepath_or_buffer parameter specifies the path to the CSV file or a buffer containing the CSV data\n",
    "# An asset is a specific dataset or file that can be validated using Great Expectations.\n",
    "# It could be a CSV file, a Pandas DataFrame, or any other type of data.\n",
    "asset = datasource.add_csv_asset(name=\"example asset\", filepath_or_buffer=\"data/example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add or update an expectation suite, which is a collection of expectations that can be used to validate data\n",
    "# Expectations are specific checks that can be applied to data to ensure it meets certain criteria\n",
    "# An expectation suite is a collection of expectations that can be used to validate data.\n",
    "# It defines the rules for what the data should look like, and it can be used to validate data against those rules.\n",
    "expectation_suite = context.add_or_update_expectation_suite(\"example expectation suite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19555c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a validator object, which is an object that can be used to validate data against an expectation suite\n",
    "# The batch_request parameter specifies the data to be validated, and the expectation_suite parameter specifies the expectations to apply\n",
    "# A validator object is used to interactively define expectations for the expectation suite.\n",
    "# The batch_request is used essentially as an example and provides instant feedback on whether the expectations are met.\n",
    "validator = context.get_validator(\n",
    "    batch_request=asset.build_batch_request(),\n",
    "    expectation_suite=expectation_suite,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first few rows of the data to be validated, which can be useful for debugging or exploring the data\n",
    "validator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb57939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an expectation with the validator that checks the number of rows in the data\n",
    "# In this case, we're expecting the number of rows to be between 1 and 100\n",
    "validator.expect_table_row_count_to_be_between(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an expectation with the validator that checks the values in a specific column\n",
    "# In this case, we're expecting the values in the \"fruit\" column to be one of \"apple\", \"banana\", or \"grapefruit\"\n",
    "validator.expect_column_values_to_be_in_set(column=\"fruit\", value_set=[\"apple\", \"banana\", \"grapefruit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the expectation suite to the context, which allows it to be reused later\n",
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ea9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add or update a checkpoint, which is a named collection of expectations and data that can be run together\n",
    "# A checkpoint bundles together data, set of expectations, and further actions to be taken after the validation.\n",
    "# A checkpoint can take in n number of data and expectation pairings.\n",
    "# The actions that can be taken after the validation are for example:\n",
    "# - Store the results\n",
    "# - Generate a report\n",
    "# - Send out a message\n",
    "# The default actions are to store the results in a file and generate a report.\n",
    "# The validator object contains the definitions for data and expectations.\n",
    "checkpoint =  context.add_or_update_checkpoint(name=\"example checkpoint\", validator=validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the checkpoint, which validates the data against the expectations and returns the results\n",
    "result = checkpoint.run()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
